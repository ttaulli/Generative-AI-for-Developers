{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e79d4e",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f47c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409becd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c95783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', temperature=1, max_tokens=100)\n",
    "response = llm('Write a tweet about large-language models.')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = llm.generate(['what is the capital of the U.S.?', 'What is the best color?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60493fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "  AIMessage,\n",
    "  HumanMessage,\n",
    "  SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1, max_tokens=100)\n",
    "\n",
    "messages = [\n",
    "  SystemMessage(content='you are a social media expert'),\n",
    "  HumanMessage(content='write a tweet about generative ai')\n",
    "]\n",
    "\n",
    "print(response(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd23856",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "You are a expert historian\n",
    "Write a paragraph about {event} in {year}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    " input_variables=['event', 'year'],\n",
    " template=template\n",
    ")\n",
    "\n",
    "response = llm(prompt.format(event='war', year='1863'))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= LLMChain(llm=llm, prompt=prompt)\n",
    "response = chain.run({'event': 'war', 'year':'1863'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=100)\n",
    "\n",
    "first_prompt = PromptTemplate(\n",
    "input_variables=['task'],\n",
    "  template='''\n",
    "  You are a great coder.\n",
    "  Write python code to do {task}\n",
    "\n",
    "'''\n",
    ")\n",
    "\n",
    "first_chain = LLMChain(llm=first_llm, prompt=first_prompt)\n",
    "\n",
    "second_llm= ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7)\n",
    "second_prompt = PromptTemplate(\n",
    "  input_variables=['code'],\n",
    "  template='Write an explanation for this python code: {code}'\n",
    "\n",
    ")\n",
    "\n",
    "second_chain = LLMChain(llm=second_llm, prompt=second_prompt)\n",
    "\n",
    "sequential_chain =  SimpleSequentialChain(chains=[first_chain, second_chain], verbose=True)\n",
    "\n",
    "response = sequential_chain.run('average two numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d375d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia.run(\"What is a large-language model?\")             \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c805bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
